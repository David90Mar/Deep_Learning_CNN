{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential    #librerie per CNN\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras import layers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint #choose best model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVA GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n",
    "    \n",
    "    \n",
    "#se non fa errore vuol dire che sta andando con la GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 - SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dim=80000\n",
    "test_dim=20000\n",
    "n=train_dim+test_dim\n",
    "epoche=200\n",
    "larg=60\n",
    "alt=30\n",
    "batch=32\n",
    "\n",
    "dataset='immagini'\n",
    "classi=['down','up']\n",
    "tipo_col=\"grayscale\"\n",
    "lear_rate=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10378688447122119378\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4943878553\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4037778772904131608\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 58, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 58, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 56, 26, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 56, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 28, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 26, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 26, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 24, 9, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 24, 9, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 12, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 247,026\n",
      "Trainable params: 246,834\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Found 80469 images belonging to 2 classes.\n",
      "Found 20460 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.7322 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.73219, saving model to model_best_weights.h5\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 1251s 16ms/step - loss: 0.6932 - acc: 0.5012 - val_loss: 0.6931 - val_acc: 0.5016\n",
      "\n",
      "Epoch 00002: loss improved from 0.73219 to 0.69323, saving model to model_best_weights.h5\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6931 - val_acc: 0.5016\n",
      "\n",
      "Epoch 00003: loss improved from 0.69323 to 0.69317, saving model to model_best_weights.h5\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 1251s 16ms/step - loss: 0.6931 - acc: 0.5010 - val_loss: 0.6929 - val_acc: 0.5054\n",
      "\n",
      "Epoch 00004: loss improved from 0.69317 to 0.69315, saving model to model_best_weights.h5\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6931 - acc: 0.5024 - val_loss: 0.6927 - val_acc: 0.5130\n",
      "\n",
      "Epoch 00005: loss improved from 0.69315 to 0.69308, saving model to model_best_weights.h5\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 1257s 16ms/step - loss: 0.6929 - acc: 0.5070 - val_loss: 0.6929 - val_acc: 0.5141\n",
      "\n",
      "Epoch 00006: loss improved from 0.69308 to 0.69293, saving model to model_best_weights.h5\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6927 - acc: 0.5101 - val_loss: 0.6932 - val_acc: 0.5083\n",
      "\n",
      "Epoch 00007: loss improved from 0.69293 to 0.69273, saving model to model_best_weights.h5\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6925 - acc: 0.5132 - val_loss: 0.6933 - val_acc: 0.5065\n",
      "\n",
      "Epoch 00008: loss improved from 0.69273 to 0.69255, saving model to model_best_weights.h5\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6923 - acc: 0.5157 - val_loss: 0.6933 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00009: loss improved from 0.69255 to 0.69234, saving model to model_best_weights.h5\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 1258s 16ms/step - loss: 0.6921 - acc: 0.5185 - val_loss: 0.6930 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00010: loss improved from 0.69234 to 0.69214, saving model to model_best_weights.h5\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6920 - acc: 0.5200 - val_loss: 0.6929 - val_acc: 0.5071\n",
      "\n",
      "Epoch 00011: loss improved from 0.69214 to 0.69201, saving model to model_best_weights.h5\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 1264s 16ms/step - loss: 0.6918 - acc: 0.5219 - val_loss: 0.6928 - val_acc: 0.5104\n",
      "\n",
      "Epoch 00012: loss improved from 0.69201 to 0.69179, saving model to model_best_weights.h5\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 1262s 16ms/step - loss: 0.6917 - acc: 0.5235 - val_loss: 0.6927 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00013: loss improved from 0.69179 to 0.69166, saving model to model_best_weights.h5\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6915 - acc: 0.5246 - val_loss: 0.6928 - val_acc: 0.5124\n",
      "\n",
      "Epoch 00014: loss improved from 0.69166 to 0.69147, saving model to model_best_weights.h5\n",
      "Epoch 15/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6913 - acc: 0.5256 - val_loss: 0.6929 - val_acc: 0.5134\n",
      "\n",
      "Epoch 00015: loss improved from 0.69147 to 0.69131, saving model to model_best_weights.h5\n",
      "Epoch 16/200\n",
      "80000/80000 [==============================] - 1258s 16ms/step - loss: 0.6911 - acc: 0.5269 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "\n",
      "Epoch 00016: loss improved from 0.69131 to 0.69112, saving model to model_best_weights.h5\n",
      "Epoch 17/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6909 - acc: 0.5283 - val_loss: 0.6930 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00017: loss improved from 0.69112 to 0.69088, saving model to model_best_weights.h5\n",
      "Epoch 18/200\n",
      "80000/80000 [==============================] - 1260s 16ms/step - loss: 0.6907 - acc: 0.5289 - val_loss: 0.6931 - val_acc: 0.5129\n",
      "\n",
      "Epoch 00018: loss improved from 0.69088 to 0.69071, saving model to model_best_weights.h5\n",
      "Epoch 19/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6905 - acc: 0.5302 - val_loss: 0.6931 - val_acc: 0.5129\n",
      "\n",
      "Epoch 00019: loss improved from 0.69071 to 0.69050, saving model to model_best_weights.h5\n",
      "Epoch 20/200\n",
      "80000/80000 [==============================] - 1260s 16ms/step - loss: 0.6903 - acc: 0.5307 - val_loss: 0.6933 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00020: loss improved from 0.69050 to 0.69030, saving model to model_best_weights.h5\n",
      "Epoch 21/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6900 - acc: 0.5317 - val_loss: 0.6933 - val_acc: 0.5122\n",
      "\n",
      "Epoch 00021: loss improved from 0.69030 to 0.69005, saving model to model_best_weights.h5\n",
      "Epoch 22/200\n",
      "80000/80000 [==============================] - 1260s 16ms/step - loss: 0.6899 - acc: 0.5326 - val_loss: 0.6933 - val_acc: 0.5129\n",
      "\n",
      "Epoch 00022: loss improved from 0.69005 to 0.68986, saving model to model_best_weights.h5\n",
      "Epoch 23/200\n",
      "80000/80000 [==============================] - 1262s 16ms/step - loss: 0.6896 - acc: 0.5338 - val_loss: 0.6935 - val_acc: 0.5117\n",
      "\n",
      "Epoch 00023: loss improved from 0.68986 to 0.68959, saving model to model_best_weights.h5\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6894 - acc: 0.5346 - val_loss: 0.6933 - val_acc: 0.5127\n",
      "\n",
      "Epoch 00024: loss improved from 0.68959 to 0.68939, saving model to model_best_weights.h5\n",
      "Epoch 25/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6891 - acc: 0.5360 - val_loss: 0.6935 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00025: loss improved from 0.68939 to 0.68909, saving model to model_best_weights.h5\n",
      "Epoch 26/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6888 - acc: 0.5369 - val_loss: 0.6939 - val_acc: 0.5131\n",
      "\n",
      "Epoch 00026: loss improved from 0.68909 to 0.68877, saving model to model_best_weights.h5\n",
      "Epoch 27/200\n",
      "80000/80000 [==============================] - 1257s 16ms/step - loss: 0.6885 - acc: 0.5382 - val_loss: 0.6940 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00027: loss improved from 0.68877 to 0.68851, saving model to model_best_weights.h5\n",
      "Epoch 28/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6942 - val_acc: 0.5122\n",
      "\n",
      "Epoch 00028: loss improved from 0.68851 to 0.68816, saving model to model_best_weights.h5\n",
      "Epoch 29/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6877 - acc: 0.5409 - val_loss: 0.6942 - val_acc: 0.5110\n",
      "\n",
      "Epoch 00029: loss improved from 0.68816 to 0.68769, saving model to model_best_weights.h5\n",
      "Epoch 30/200\n",
      "80000/80000 [==============================] - 1255s 16ms/step - loss: 0.6872 - acc: 0.5420 - val_loss: 0.6945 - val_acc: 0.5123\n",
      "\n",
      "Epoch 00030: loss improved from 0.68769 to 0.68723, saving model to model_best_weights.h5\n",
      "Epoch 31/200\n",
      "80000/80000 [==============================] - 1258s 16ms/step - loss: 0.6869 - acc: 0.5431 - val_loss: 0.6946 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00031: loss improved from 0.68723 to 0.68686, saving model to model_best_weights.h5\n",
      "Epoch 32/200\n",
      "80000/80000 [==============================] - 1257s 16ms/step - loss: 0.6865 - acc: 0.5441 - val_loss: 0.6945 - val_acc: 0.5131\n",
      "\n",
      "Epoch 00032: loss improved from 0.68686 to 0.68647, saving model to model_best_weights.h5\n",
      "Epoch 33/200\n",
      "80000/80000 [==============================] - 1255s 16ms/step - loss: 0.6859 - acc: 0.5454 - val_loss: 0.6947 - val_acc: 0.5112\n",
      "\n",
      "Epoch 00033: loss improved from 0.68647 to 0.68586, saving model to model_best_weights.h5\n",
      "Epoch 34/200\n",
      "80000/80000 [==============================] - 1257s 16ms/step - loss: 0.6854 - acc: 0.5469 - val_loss: 0.6951 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00034: loss improved from 0.68586 to 0.68543, saving model to model_best_weights.h5\n",
      "Epoch 35/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6848 - acc: 0.5482 - val_loss: 0.6953 - val_acc: 0.5090\n",
      "\n",
      "Epoch 00035: loss improved from 0.68543 to 0.68476, saving model to model_best_weights.h5\n",
      "Epoch 36/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6841 - acc: 0.5501 - val_loss: 0.6954 - val_acc: 0.5086\n",
      "\n",
      "Epoch 00036: loss improved from 0.68476 to 0.68409, saving model to model_best_weights.h5\n",
      "Epoch 37/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6836 - acc: 0.5513 - val_loss: 0.6955 - val_acc: 0.5086\n",
      "\n",
      "Epoch 00037: loss improved from 0.68409 to 0.68360, saving model to model_best_weights.h5\n",
      "Epoch 38/200\n",
      "80000/80000 [==============================] - 1435s 18ms/step - loss: 0.6827 - acc: 0.5535 - val_loss: 0.6963 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00038: loss improved from 0.68360 to 0.68271, saving model to model_best_weights.h5\n",
      "Epoch 39/200\n",
      "80000/80000 [==============================] - 3124s 39ms/step - loss: 0.6821 - acc: 0.5550 - val_loss: 0.6962 - val_acc: 0.5086\n",
      "\n",
      "Epoch 00039: loss improved from 0.68271 to 0.68214, saving model to model_best_weights.h5\n",
      "Epoch 40/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6814 - acc: 0.5562 - val_loss: 0.6965 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00040: loss improved from 0.68214 to 0.68140, saving model to model_best_weights.h5\n",
      "Epoch 41/200\n",
      "80000/80000 [==============================] - 1254s 16ms/step - loss: 0.6803 - acc: 0.5582 - val_loss: 0.6970 - val_acc: 0.5092\n",
      "\n",
      "Epoch 00041: loss improved from 0.68140 to 0.68033, saving model to model_best_weights.h5\n",
      "Epoch 42/200\n",
      "80000/80000 [==============================] - 1255s 16ms/step - loss: 0.6795 - acc: 0.5602 - val_loss: 0.6973 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00042: loss improved from 0.68033 to 0.67948, saving model to model_best_weights.h5\n",
      "Epoch 43/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6786 - acc: 0.5615 - val_loss: 0.6977 - val_acc: 0.5076\n",
      "\n",
      "Epoch 00043: loss improved from 0.67948 to 0.67864, saving model to model_best_weights.h5\n",
      "Epoch 44/200\n",
      "80000/80000 [==============================] - 1257s 16ms/step - loss: 0.6775 - acc: 0.5646 - val_loss: 0.6983 - val_acc: 0.5077\n",
      "\n",
      "Epoch 00044: loss improved from 0.67864 to 0.67747, saving model to model_best_weights.h5\n",
      "Epoch 45/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6763 - acc: 0.5668 - val_loss: 0.6984 - val_acc: 0.5095\n",
      "\n",
      "Epoch 00045: loss improved from 0.67747 to 0.67634, saving model to model_best_weights.h5\n",
      "Epoch 46/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6753 - acc: 0.5685 - val_loss: 0.6990 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00046: loss improved from 0.67634 to 0.67530, saving model to model_best_weights.h5\n",
      "Epoch 47/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6740 - acc: 0.5710 - val_loss: 0.6996 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00047: loss improved from 0.67530 to 0.67396, saving model to model_best_weights.h5\n",
      "Epoch 48/200\n",
      "80000/80000 [==============================] - 1259s 16ms/step - loss: 0.6728 - acc: 0.5730 - val_loss: 0.7006 - val_acc: 0.5058\n",
      "\n",
      "Epoch 00048: loss improved from 0.67396 to 0.67275, saving model to model_best_weights.h5\n",
      "Epoch 49/200\n",
      "80000/80000 [==============================] - 1377s 17ms/step - loss: 0.6720 - acc: 0.5743 - val_loss: 0.6999 - val_acc: 0.5057\n",
      "\n",
      "Epoch 00049: loss improved from 0.67275 to 0.67196, saving model to model_best_weights.h5\n",
      "Epoch 50/200\n",
      "80000/80000 [==============================] - 5319s 66ms/step - loss: 0.6706 - acc: 0.5767 - val_loss: 0.7015 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00050: loss improved from 0.67196 to 0.67057, saving model to model_best_weights.h5\n",
      "Epoch 51/200\n",
      "80000/80000 [==============================] - 1265s 16ms/step - loss: 0.6694 - acc: 0.5789 - val_loss: 0.7022 - val_acc: 0.5041\n",
      "\n",
      "Epoch 00051: loss improved from 0.67057 to 0.66941, saving model to model_best_weights.h5\n",
      "Epoch 52/200\n",
      "80000/80000 [==============================] - 1262s 16ms/step - loss: 0.6680 - acc: 0.5815 - val_loss: 0.7021 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00052: loss improved from 0.66941 to 0.66803, saving model to model_best_weights.h5\n",
      "Epoch 53/200\n",
      "80000/80000 [==============================] - 1263s 16ms/step - loss: 0.6668 - acc: 0.5832 - val_loss: 0.7026 - val_acc: 0.5074\n",
      "\n",
      "Epoch 00053: loss improved from 0.66803 to 0.66684, saving model to model_best_weights.h5\n",
      "Epoch 54/200\n",
      "80000/80000 [==============================] - 1260s 16ms/step - loss: 0.6655 - acc: 0.5851 - val_loss: 0.7031 - val_acc: 0.5072\n",
      "\n",
      "Epoch 00054: loss improved from 0.66684 to 0.66554, saving model to model_best_weights.h5\n",
      "Epoch 55/200\n",
      "80000/80000 [==============================] - 1261s 16ms/step - loss: 0.6641 - acc: 0.5876 - val_loss: 0.7037 - val_acc: 0.5076\n",
      "\n",
      "Epoch 00055: loss improved from 0.66554 to 0.66412, saving model to model_best_weights.h5\n",
      "Epoch 56/200\n",
      "80000/80000 [==============================] - 1261s 16ms/step - loss: 0.6628 - acc: 0.5897 - val_loss: 0.7041 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00056: loss improved from 0.66412 to 0.66278, saving model to model_best_weights.h5\n",
      "Epoch 57/200\n",
      "80000/80000 [==============================] - 1260s 16ms/step - loss: 0.6615 - acc: 0.5918 - val_loss: 0.7046 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00057: loss improved from 0.66278 to 0.66154, saving model to model_best_weights.h5\n",
      "Epoch 58/200\n",
      "80000/80000 [==============================] - 1261s 16ms/step - loss: 0.6602 - acc: 0.5936 - val_loss: 0.7054 - val_acc: 0.5059\n",
      "\n",
      "Epoch 00058: loss improved from 0.66154 to 0.66021, saving model to model_best_weights.h5\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6586 - acc: 0.5958 - val_loss: 0.7061 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00059: loss improved from 0.66021 to 0.65862, saving model to model_best_weights.h5\n",
      "Epoch 60/200\n",
      "80000/80000 [==============================] - 1251s 16ms/step - loss: 0.6576 - acc: 0.5979 - val_loss: 0.7064 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00060: loss improved from 0.65862 to 0.65755, saving model to model_best_weights.h5\n",
      "Epoch 61/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6564 - acc: 0.5997 - val_loss: 0.7070 - val_acc: 0.5065\n",
      "\n",
      "Epoch 00061: loss improved from 0.65755 to 0.65638, saving model to model_best_weights.h5\n",
      "Epoch 62/200\n",
      "80000/80000 [==============================] - 1251s 16ms/step - loss: 0.6547 - acc: 0.6019 - val_loss: 0.7075 - val_acc: 0.5062\n",
      "\n",
      "Epoch 00062: loss improved from 0.65638 to 0.65473, saving model to model_best_weights.h5\n",
      "Epoch 63/200\n",
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6539 - acc: 0.6030 - val_loss: 0.7078 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00063: loss improved from 0.65473 to 0.65389, saving model to model_best_weights.h5\n",
      "Epoch 64/200\n",
      "80000/80000 [==============================] - 1256s 16ms/step - loss: 0.6524 - acc: 0.6052 - val_loss: 0.7088 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00064: loss improved from 0.65389 to 0.65241, saving model to model_best_weights.h5\n",
      "Epoch 65/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6515 - acc: 0.6066 - val_loss: 0.7090 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00065: loss improved from 0.65241 to 0.65147, saving model to model_best_weights.h5\n",
      "Epoch 66/200\n",
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6502 - acc: 0.6085 - val_loss: 0.7098 - val_acc: 0.5071\n",
      "\n",
      "Epoch 00066: loss improved from 0.65147 to 0.65024, saving model to model_best_weights.h5\n",
      "Epoch 67/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.6488 - acc: 0.6104 - val_loss: 0.7105 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00067: loss improved from 0.65024 to 0.64882, saving model to model_best_weights.h5\n",
      "Epoch 68/200\n",
      "80000/80000 [==============================] - 1252s 16ms/step - loss: 0.6479 - acc: 0.6118 - val_loss: 0.7106 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00068: loss improved from 0.64882 to 0.64794, saving model to model_best_weights.h5\n",
      "Epoch 69/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.6467 - acc: 0.6133 - val_loss: 0.7104 - val_acc: 0.5066\n",
      "\n",
      "Epoch 00069: loss improved from 0.64794 to 0.64668, saving model to model_best_weights.h5\n",
      "Epoch 70/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.6455 - acc: 0.6154 - val_loss: 0.7111 - val_acc: 0.5046\n",
      "\n",
      "Epoch 00070: loss improved from 0.64668 to 0.64550, saving model to model_best_weights.h5\n",
      "Epoch 71/200\n",
      "80000/80000 [==============================] - 1249s 16ms/step - loss: 0.6440 - acc: 0.6171 - val_loss: 0.7117 - val_acc: 0.5042\n",
      "\n",
      "Epoch 00071: loss improved from 0.64550 to 0.64405, saving model to model_best_weights.h5\n",
      "Epoch 72/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6430 - acc: 0.6183 - val_loss: 0.7124 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00072: loss improved from 0.64405 to 0.64303, saving model to model_best_weights.h5\n",
      "Epoch 73/200\n",
      "80000/80000 [==============================] - 1250s 16ms/step - loss: 0.6420 - acc: 0.6198 - val_loss: 0.7130 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00073: loss improved from 0.64303 to 0.64195, saving model to model_best_weights.h5\n",
      "Epoch 74/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6408 - acc: 0.6213 - val_loss: 0.7135 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00074: loss improved from 0.64195 to 0.64084, saving model to model_best_weights.h5\n",
      "Epoch 75/200\n",
      "80000/80000 [==============================] - 1249s 16ms/step - loss: 0.6397 - acc: 0.6228 - val_loss: 0.7137 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00075: loss improved from 0.64084 to 0.63966, saving model to model_best_weights.h5\n",
      "Epoch 76/200\n",
      "80000/80000 [==============================] - 1249s 16ms/step - loss: 0.6384 - acc: 0.6244 - val_loss: 0.7136 - val_acc: 0.5046\n",
      "\n",
      "Epoch 00076: loss improved from 0.63966 to 0.63843, saving model to model_best_weights.h5\n",
      "Epoch 77/200\n",
      "80000/80000 [==============================] - 1249s 16ms/step - loss: 0.6374 - acc: 0.6257 - val_loss: 0.7147 - val_acc: 0.5036\n",
      "\n",
      "Epoch 00077: loss improved from 0.63843 to 0.63744, saving model to model_best_weights.h5\n",
      "Epoch 78/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6367 - acc: 0.6267 - val_loss: 0.7145 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00078: loss improved from 0.63744 to 0.63672, saving model to model_best_weights.h5\n",
      "Epoch 79/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6356 - acc: 0.6280 - val_loss: 0.7149 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00079: loss improved from 0.63672 to 0.63564, saving model to model_best_weights.h5\n",
      "Epoch 80/200\n",
      "80000/80000 [==============================] - 1247s 16ms/step - loss: 0.6342 - acc: 0.6301 - val_loss: 0.7153 - val_acc: 0.5058\n",
      "\n",
      "Epoch 00080: loss improved from 0.63564 to 0.63419, saving model to model_best_weights.h5\n",
      "Epoch 81/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6335 - acc: 0.6310 - val_loss: 0.7164 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00081: loss improved from 0.63419 to 0.63349, saving model to model_best_weights.h5\n",
      "Epoch 82/200\n",
      "80000/80000 [==============================] - 1248s 16ms/step - loss: 0.6325 - acc: 0.6323 - val_loss: 0.7164 - val_acc: 0.5041\n",
      "\n",
      "Epoch 00082: loss improved from 0.63349 to 0.63246, saving model to model_best_weights.h5\n",
      "Epoch 83/200\n",
      "80000/80000 [==============================] - 1249s 16ms/step - loss: 0.6316 - acc: 0.6333 - val_loss: 0.7165 - val_acc: 0.5057\n",
      "\n",
      "Epoch 00083: loss improved from 0.63246 to 0.63162, saving model to model_best_weights.h5\n",
      "Epoch 84/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6305 - acc: 0.6346 - val_loss: 0.7170 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00084: loss improved from 0.63162 to 0.63053, saving model to model_best_weights.h5\n",
      "Epoch 85/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6299 - acc: 0.6350 - val_loss: 0.7171 - val_acc: 0.5056\n",
      "\n",
      "Epoch 00085: loss improved from 0.63053 to 0.62987, saving model to model_best_weights.h5\n",
      "Epoch 86/200\n",
      "80000/80000 [==============================] - 1253s 16ms/step - loss: 0.6288 - acc: 0.6363 - val_loss: 0.7177 - val_acc: 0.5056\n",
      "\n",
      "Epoch 00086: loss improved from 0.62987 to 0.62880, saving model to model_best_weights.h5\n",
      "Epoch 87/200\n",
      "45027/80000 [===============>..............] - ETA: 7:53 - loss: 0.6276 - acc: 0.6377"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "with tf.device('/gpu:0'):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    classifier.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',\n",
    "                     input_shape = (larg, alt, 1),strides=1, padding='valid'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    classifier.add(layers.Dropout(0.60))\n",
    "\n",
    "    classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    classifier.add(layers.Dropout(0.60))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(128, activation='relu'))\n",
    "    classifier.add(layers.Dropout(0.25))\n",
    "    classifier.add(Dense(256, activation='relu'))\n",
    "    classifier.add(layers.Dropout(0.60))\n",
    "    classifier.add(Dense(len(classi), activation='softmax'))\n",
    "    classifier.summary()\n",
    "    \n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    optimizer = Adam(lr=lear_rate)\n",
    "    classifier.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    # Part 2 - Fitting the CNN to the images\n",
    "\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    #applichiamo delle traformazioni casuacategorical_crossentropyli per aumentare il numero di esempi nel training\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(r'C:\\Users\\user\\Desktop\\Data_Science\\CNN\\immagini\\training',\n",
    "                                                     target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                     color_mode=tipo_col,  #se rgb o grayscale\n",
    "                                                     classes = classi, #classi in cui farà predizione\n",
    "                                                     batch_size = batch,\n",
    "                                                     class_mode = 'categorical',#se la classe è binaria o meno \n",
    "                                                     shuffle=True)  #se pesca casuamente il dato dal dataset\n",
    "\n",
    "    # NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "    # tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "    #ripetiamo la stessa cosa anche per il test set        \n",
    "    test_set = test_datagen.flow_from_directory(r'C:\\Users\\user\\Desktop\\Data_Science\\CNN\\immagini\\testing',\n",
    "                                                target_size = (larg, alt),\n",
    "                                                batch_size = batch,\n",
    "                                                color_mode=tipo_col,\n",
    "                                                classes = classi,\n",
    "                                               class_mode = 'categorical',\n",
    "                                               shuffle=True)\n",
    "                    #CHECKPOINT salva sul disco, i modelli migliori\n",
    "    #early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "    checkpoint = ModelCheckpoint('model_best_weights.h5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "\n",
    "    classifier.fit_generator(training_set,\n",
    "                             steps_per_epoch = train_dim,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                             epochs = epoche,\n",
    "                             validation_data = test_set,\n",
    "                             validation_steps = test_dim,verbose=1,callbacks = [checkpoint])   #corrisponde al numero di immagini nel mio test set\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVA RETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> [Dense -> Dropout]*2 -> Softmax\n",
    "\"\"\"\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (larg, alt, 1)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(layers.Dropout(0.40))\n",
    "\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(layers.Dropout(0.40))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(512, activation='relu'))\n",
    "classifier.add(layers.Dropout(0.25))\n",
    "classifier.add(Dense(1024, activation='relu'))\n",
    "classifier.add(layers.Dropout(0.50))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.summary()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> [Dense -> Dropout]*2 -> Softmax\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',\n",
    "                 input_shape = (larg, alt, 1),strides=1, padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "classifier.add(layers.Dropout(0.60))\n",
    "\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',kernel_initializer='he_normal',strides=1, padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "classifier.add(layers.Dropout(0.60))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(layers.Dropout(0.25))\n",
    "classifier.add(Dense(256, activation='relu'))\n",
    "classifier.add(layers.Dropout(0.60))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(lr=lear_rate)\n",
    "classifier.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#applichiamo delle traformazioni casuacategorical_crossentropyli per aumentare il numero di esempi nel training\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(dataset+'/training',\n",
    "                                                 target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                 color_mode=tipo_col,  #se rgb o grayscale\n",
    "                                                 classes = classi, #classi in cui farà predizione\n",
    "                                                 batch_size = batch,\n",
    "                                                 class_mode = 'categorical',#se la classe è binaria o meno \n",
    "                                                 shuffle=True)  #se pesca casuamente il dato dal dataset\n",
    "                                                 \n",
    "# NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "# tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "#ripetiamo la stessa cosa anche per il test set        \n",
    "test_set = test_datagen.flow_from_directory(dataset+'/training',\n",
    "                                            target_size = (larg, alt),\n",
    "                                            batch_size = batch,\n",
    "                                            color_mode=tipo_col,\n",
    "                                            classes = classi,\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle=True)\n",
    "                #CHECKPOINT salva sul disco, i modelli migliori\n",
    "#early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint('model_best_weights.h5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "                             \n",
    "                             \n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = train_dim,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                         epochs = epoche,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = test_dim,verbose=1,callbacks = [checkpoint])   #corrisponde al numero di immagini nel mio test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(96, (3, 3), input_shape = (larg, alt, 1), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(96, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(96, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(192, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(384, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 96*3, activation = 'relu'))\n",
    "classifier.add(layers.Dropout(0.3))\n",
    "\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "#opt = SGD(lr=0.1)\n",
    "opt=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "classifier.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy',f1])\n",
    "\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#applichiamo delle traformazioni casuacategorical_crossentropyli per aumentare il numero di esempi nel training\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False) #se la classe è binaria o meno \n",
    "                                                 \n",
    "# NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "# tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "#ripetiamo la stessa cosa anche per il test set        \n",
    "test_set = test_datagen.flow_from_directory('dataset/testing',\n",
    "                                            target_size = (larg, alt),\n",
    "                                            batch_size = 32,\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle=False)\n",
    "\n",
    "history=classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = train_dim-200000,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                         epochs = epoche-40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = test_dim-100000,verbose=1,workers=4)   #corrisponde al numero di immagini nel mio test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(60, (3, 3), input_shape = (larg, alt, 1), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(40, (3, 3), activation = 'relu',kernel_initializer='he_normal'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(20, (3, 3), activation = 'relu',kernel_initializer='he_normal'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(16, (3, 3), activation = 'relu',kernel_initializer='he_normal'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "#classifier.add(layers.Dropout(0.4))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 20, activation = 'relu',kernel_initializer='he_normal'))\n",
    "classifier.add(layers.Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.000000005)\n",
    "classifier.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy',f1])\n",
    "\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#applichiamo delle traformazioni casuali per aumentare il numero di esempi nel training\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False) #se la classe è binaria o meno \n",
    "                                                 \n",
    "# NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "# tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "#ripetiamo la stessa cosa anche per il test set        \n",
    "test_set = test_datagen.flow_from_directory('dataset/testing',\n",
    "                                            target_size = (larg, alt),\n",
    "                                            batch_size = 32,\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle=False)\n",
    "\n",
    "history=classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = train_dim,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                         epochs =epoche+40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = test_dim,verbose=1,workers=4)   #corrisponde al numero di immagini nel mio test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "seed = 7\n",
    "\n",
    "#Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(30, 20, 20, activation = 'relu', input_shape = (larg, alt, 1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(10, 20, 20, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(10, 10, 10, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(5, 10, 10, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(3, 10, 10, activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "# Flatten the 3D output to 1D tensor for a fully connected layer to accept the input\n",
    "model.add(Flatten())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax')) #Last layer with one output per class\n",
    "\n",
    "# The function to optimize is the cross entropy between the true label and the output (softmax) of the model\n",
    "# We will use adadelta to do the gradient descent see http://cs231n.github.io/neural-networks-3/#ada\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#applichiamo delle traformazioni casuali per aumentare il numero di esempi nel training\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size = 512,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True) #se la classe è binaria o meno \n",
    "                                                 \n",
    "# NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "# tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "#ripetiamo la stessa cosa anche per il test set        \n",
    "test_set = test_datagen.flow_from_directory('dataset/testing',\n",
    "                                            target_size = (larg, alt),\n",
    "                                            batch_size = 512,\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle=True)\n",
    "#Time-Based Learning Rate Schedule\n",
    "\n",
    "\n",
    "#epochs = 10\n",
    "#learning_rate = 0.01\n",
    "#decay_rate = learning_rate / epochs\n",
    "#momentum = 0.8\n",
    "#sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# Fit the model\n",
    "\n",
    "#Drop-Based Learning Rate Schedule\n",
    "\n",
    "\n",
    "\n",
    "opt=optimizers.Adagrad(lr=0.00005, epsilon=1e-08, decay=0.0)\n",
    "#keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "#keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#opt=optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy',f1])\n",
    "# learning schedule callback\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\"result/\"+filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history=model.fit_generator(training_set,\n",
    "                         steps_per_epoch = train_dim,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                         epochs = epoche+20,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = test_dim,\n",
    "                         verbose=1)   #corrisponde al numero di immagini nel mio test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlwzNet\n",
    "from keras.layers import ZeroPadding2D\n",
    "k=1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(int(16*k), 5, 5, activation = 'relu', input_shape = (larg, alt, 1)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(16*k), 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(32*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(32*k), 3, 3, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(64*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(64*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(64*k), 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(128*k), 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(256*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(int(256*k), 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(Conv2D(int(256*k), 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(int(1024*k), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(int(1024*k), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The function to optimize is the cross entropy between the true label and the output (softmax) of the model\n",
    "# We will use adadelta to do the gradient descent see http://cs231n.github.io/neural-networks-3/#ada\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#applichiamo delle traformazioni casuali per aumentare il numero di esempi nel training\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training',\n",
    "                                                 target_size = (larg, alt), #dimensione in ingresso alla cnn\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 batch_size = batch,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False) #se la classe è binaria o meno \n",
    "                                                 \n",
    "# NB per aumentare ulteriormente le perfomance si potrebbe aumentare la dimensione delle immagini in ingresso,\n",
    "# tuttavia il tempo necessario all'esecuzione aumenta notevolemente                                                 \n",
    "\n",
    "#ripetiamo la stessa cosa anche per il test set        \n",
    "test_set = test_datagen.flow_from_directory('dataset/testing',\n",
    "                                            target_size = (larg, alt),\n",
    "                                            batch_size = batch,\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle=False)\n",
    "#Time-Based Learning Rate Schedule\n",
    "\n",
    "\n",
    "#epochs = 10\n",
    "#learning_rate = 0.01\n",
    "#decay_rate = learning_rate / epoche\n",
    "#momentum = 0.8\n",
    "#opt = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# Fit the model\n",
    "\n",
    "#Drop-Based Learning Rate Schedule\n",
    "\n",
    "\n",
    "\n",
    "#keras.optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "#keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "#keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "opt=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy',f1])\n",
    "# learning schedule callback\n",
    "\n",
    "\n",
    "history=model.fit_generator(training_set,\n",
    "                         steps_per_epoch = train_dim,   #numero di immagini nel trainig set (tutte le osservazioni vengono passate durante ogni epoca)\n",
    "                         epochs = epoche,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = test_dim,\n",
    "                         verbose=1)   #corrisponde al numero di immagini nel mio test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"model_best_weights.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K.image_data_format()) # print current format\n",
    "K.set_image_data_format() # set format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "model=load_model(\"model_best_weights_59-150000.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primo\n",
      "secondo\n",
      "terzo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "punti_up=0\n",
    "punti_down=0\n",
    "punti_neutral=0\n",
    "ktup=0\n",
    "ktdown=0\n",
    "ktneu=0\n",
    "\n",
    "rag=1000000\n",
    "l=[]\n",
    "print(\"primo\")\n",
    "for raggio in range(0,rag):\n",
    "    #print(str(raggio/rag))\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_image = image.load_img('dataset_new2/training/up/X'+str(raggio)+'.png', target_size = (44, 33),grayscale=True)\n",
    "        #il passo precedente non basta perchè in ingresso alla rete abbiamo un oggetto di dimensione 64x64x3 (immagine a colori)\n",
    "        #quindi usiamo il comando successivo per creare il vettore 3D\n",
    "\n",
    "        test_image = image.img_to_array(test_image)\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis = 0)/255\n",
    "\n",
    "\n",
    "        if model.predict(test_image)[0].argmax() == 0:\n",
    "            punti_up+=1\n",
    "        else: pass\n",
    "\n",
    "\n",
    "\n",
    "        ktup+=1 \n",
    "\n",
    "    except:\n",
    "\n",
    "        pass\n",
    "\n",
    "print(\"secondo\")\n",
    "\n",
    "for raggio in range(0,rag):\n",
    "    #print(str(raggio/len(l)))\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_image = image.load_img('dataset_new2/training/down/X'+str(raggio)+'.png', target_size = (44, 33),grayscale=True)\n",
    "        #il passo precedente non basta perchè in ingresso alla rete abbiamo un oggetto di dimensione 64x64x3 (immagine a colori)\n",
    "        #quindi usiamo il comando successivo per creare il vettore 3D\n",
    "\n",
    "        test_image = image.img_to_array(test_image)\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis = 0)/255\n",
    "\n",
    "\n",
    "        if model.predict(test_image)[0].argmax() == 1:\n",
    "            punti_down+=1\n",
    "\n",
    "        else: pass\n",
    "\n",
    "\n",
    "\n",
    "        ktdown+=1 \n",
    "\n",
    "    except:\n",
    "\n",
    "        pass    \n",
    "\n",
    "print(\"terzo\")\n",
    "\n",
    "for raggio in range(0,rag):\n",
    "    #print(str(raggio/len(l)))\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_image = image.load_img('dataset_new2/training/neutral/X'+str(raggio)+'.png', target_size = (44, 33),grayscale=True)\n",
    "        #il passo precedente non basta perchè in ingresso alla rete abbiamo un oggetto di dimensione 64x64x3 (immagine a colori)\n",
    "        #quindi usiamo il comando successivo per creare il vettore 3D\n",
    "\n",
    "        test_image = image.img_to_array(test_image)\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis = 0)/255\n",
    "\n",
    "\n",
    "        if model.predict(test_image)[0].argmax() == 2:\n",
    "            punti_neutral+=1\n",
    "        else: pass\n",
    "\n",
    "\n",
    "        ktneu+=1 \n",
    "\n",
    "    except:\n",
    "\n",
    "        pass \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=(punti_up+punti_dow+punti_neutral)/(ktup+ktdown+ktneu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3044103189938642"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punti_neutral/ktneu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431048"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(punti_up+punti_dow+punti_neutral)/(((punti_up+punti_dow+punti_neutral)+))\n",
    "\n",
    "TP/(TP+ FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "model=load_model(\"model_best_weights_044.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "test_image = image.load_img('dataset_new2/training/up/X100.png', target_size = (44, 33),grayscale=True)\n",
    "#il passo precedente non basta perchè in ingresso alla rete abbiamo un oggetto di dimensione 64x64x3 (immagine a colori)\n",
    "#quindi usiamo il comando successivo per creare il vettore 3D\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis = 0)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_image)[0].argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
